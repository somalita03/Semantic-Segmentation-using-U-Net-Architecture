# -*- coding: utf-8 -*-
"""Semantic_Segmentation_on_Camvid_Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RODRzjT75YQqR7WyWYN8e_keC2oqCpVl
"""

from google.colab import drive
drive.mount('/content/drive')

! pip install kaggle

"""Need to upload one's kaggle json file."""

! mkdir -p ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d carlolepelaars/camvid

from zipfile import ZipFile
dataset = '/content/camvid.zip'
with ZipFile(dataset,'r') as zip_file:
  zip_file.extractall()
  print("done")

import os
import numpy as np
import pandas as pd
import re
import matplotlib.pyplot as plt
import cv2
import tensorflow as tf

import os
import cv2
import shutil

# Define directories
directories = ['/content/CamVid/train', '/content/CamVid/train_labels', '/content/CamVid/val', '/content/CamVid/val_labels', '/content/CamVid/test', '/content/CamVid/test_labels']
output_dir = 'data/resized_data'  # New directory to save resized images and labels

# Create the output directory
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Resize function
def resize_images(input_dir, output_dir):
    files = os.listdir(input_dir)
    for file in files:
        input_path = os.path.join(input_dir, file)
        output_path = os.path.join(output_dir, file)
        img = cv2.imread(input_path)
        resized_img = cv2.resize(img, (256, 256))  # Resize image to 128x128
        cv2.imwrite(output_path, resized_img)  # Save resized image

# Resize images and labels for all directories
for directory in directories:
    input_dir = directory
    output_subdir = os.path.join(output_dir, os.path.basename(directory))
    if not os.path.exists(output_subdir):
        os.makedirs(output_subdir)
    resize_images(input_dir, output_subdir)

print("Resizing and saving complete.")

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, Callback
from sklearn.metrics import precision_recall_curve, accuracy_score, confusion_matrix
import seaborn as sns

# Setup paths
train_images_dir = '/content/data/resized_data/train'
train_labels_dir = '/content/data/resized_data/train_labels'

def one_hot_encode(masks, num_classes):
    """ Convert masks to one-hot encoded format """
    masks_encoded = np.zeros((*masks.shape, num_classes), dtype=np.float32)
    for i in range(num_classes):
        masks_encoded[masks == i, i] = 1
    return masks_encoded

def LoadData(imgPath, maskPath, num_classes, shape=256):
    imgNames = os.listdir(imgPath)
    maskNames = [re.sub('\.png', '_L.png', mem) for mem in imgNames]

    imgAddr = imgPath + '/'
    maskAddr = maskPath + '/'

    images = []
    masks = []

    for i in range(len(imgNames)):
        img = plt.imread(imgAddr + imgNames[i])
        mask = plt.imread(maskAddr + maskNames[i])

        img = cv2.resize(img, (shape, shape))
        mask = cv2.resize(mask, (shape, shape))

        # Assuming mask is RGB and needs to be converted to class indices
        mask = np.argmax(mask, axis=-1)  # Convert RGB masks to class indices

        images.append(img)
        masks.append(mask)

    return np.array(images), one_hot_encode(np.array(masks), num_classes)

# Load training data
num_classes = 32
X_train, y_train = LoadData(train_images_dir, train_labels_dir, num_classes, shape=256)

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

def GiveMeUnet(inputs, numFilters=16, dropout=0.1, doBatchNorm=True, numClasses=32):
    # Encoding path
    c1 = Conv2D(numFilters, (3, 3), activation='relu', padding='same')(inputs)
    if doBatchNorm:
        from tensorflow.keras.layers import BatchNormalization
        c1 = BatchNormalization()(c1)
    c1 = Conv2D(numFilters, (3, 3), activation='relu', padding='same')(c1)
    if doBatchNorm:
        c1 = BatchNormalization()(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(numFilters*2, (3, 3), activation='relu', padding='same')(p1)
    if doBatchNorm:
        c2 = BatchNormalization()(c2)
    c2 = Conv2D(numFilters*2, (3, 3), activation='relu', padding='same')(c2)
    if doBatchNorm:
        c2 = BatchNormalization()(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(numFilters*4, (3, 3), activation='relu', padding='same')(p2)
    if doBatchNorm:
        c3 = BatchNormalization()(c3)
    c3 = Conv2D(numFilters*4, (3, 3), activation='relu', padding='same')(c3)
    if doBatchNorm:
        c3 = BatchNormalization()(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    # Bottleneck
    b1 = Conv2D(numFilters*8, (3, 3), activation='relu', padding='same')(p3)
    if doBatchNorm:
        b1 = BatchNormalization()(b1)
    b1 = Conv2D(numFilters*8, (3, 3), activation='relu', padding='same')(b1)
    if doBatchNorm:
        b1 = BatchNormalization()(b1)

    # Decoding path
    u1 = UpSampling2D((2, 2))(b1)
    u1 = concatenate([u1, c3])
    c4 = Conv2D(numFilters*4, (3, 3), activation='relu', padding='same')(u1)
    if doBatchNorm:
        c4 = BatchNormalization()(c4)
    c4 = Conv2D(numFilters*4, (3, 3), activation='relu', padding='same')(c4)
    if doBatchNorm:
        c4 = BatchNormalization()(c4)

    u2 = UpSampling2D((2, 2))(c4)
    u2 = concatenate([u2, c2])
    c5 = Conv2D(numFilters*2, (3, 3), activation='relu', padding='same')(u2)
    if doBatchNorm:
        c5 = BatchNormalization()(c5)
    c5 = Conv2D(numFilters*2, (3, 3), activation='relu', padding='same')(c5)
    if doBatchNorm:
        c5 = BatchNormalization()(c5)

    u3 = UpSampling2D((2, 2))(c5)
    u3 = concatenate([u3, c1])
    c6 = Conv2D(numFilters, (3, 3), activation='relu', padding='same')(u3)
    if doBatchNorm:
        c6 = BatchNormalization()(c6)
    c6 = Conv2D(numFilters, (3, 3), activation='relu', padding='same')(c6)
    if doBatchNorm:
        c6 = BatchNormalization()(c6)

    # Output layer
    outputs = Conv2D(numClasses, (1, 1), activation='softmax')(c6)

    model = Model(inputs=[inputs], outputs=[outputs])
    return model

# Define model
inputs = Input((256, 256, 3))
model = GiveMeUnet(inputs, numFilters=16, dropout=0.1, doBatchNorm=True, numClasses=num_classes)
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint_callback = ModelCheckpoint('/content/data/best_weights.keras', save_best_only=True, monitor='loss', mode='min', verbose=1)

history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=4,
    verbose=1,
    callbacks=[checkpoint_callback]
)

import matplotlib.pyplot as plt

def plot_metrics(history):
    plt.figure()
    plt.plot(history.history['accuracy'], label='Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Accuracy over epochs')
    plt.show()

    plt.figure()
    plt.plot(history.history['loss'], label='Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Loss over epochs')
    plt.show()

plot_metrics(history)

import numpy as np
import os
from PIL import Image
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt

# Paths to directories
train_images_dir = '/content/data/resized_data/train'
train_labels_dir = '/content/data/resized_data/train_labels'
val_images_dir = '/content/data/resized_data/val'
val_labels_dir = '/content/data/resized_data/val_labels'

# Load and resize images from directory
def load_and_resize_images_from_directory(directory, target_size=(256, 256)):
    images = []
    for file in sorted(os.listdir(directory)):
        if file.endswith('.png'):
            img_path = os.path.join(directory, file)
            img = Image.open(img_path).convert('RGB')
            img = img.resize(target_size, Image.LANCZOS)
            images.append(np.array(img))
    return np.array(images)

# Load datasets with resizing
train_images = load_and_resize_images_from_directory(train_images_dir)
train_labels = load_and_resize_images_from_directory(train_labels_dir)
val_images = load_and_resize_images_from_directory(val_images_dir)
val_labels = load_and_resize_images_from_directory(val_labels_dir)

# Normalize the images
train_images = train_images.astype('float32') / 255.0
val_images = val_images.astype('float32') / 255.0

# Convert RGB labels to one-hot encoding
def rgb_to_one_hot(labels, num_classes):
    one_hot_labels = np.zeros((labels.shape[0], labels.shape[1], labels.shape[2], num_classes))
    for i in range(num_classes):
        one_hot_labels[..., i] = np.all(labels == np.array(COLOR_MAP[i]), axis=-1)
    return one_hot_labels

# Define a color map for conversion
COLOR_MAP = [
    [64, 128, 64], [192, 0, 128], [0, 128, 192], [0, 128, 64], [128, 0, 0],
    [64, 0, 128], [64, 0, 192], [192, 128, 64], [192, 192, 128], [64, 64, 128],
    [128, 0, 192], [192, 0, 64], [128, 128, 64], [192, 0, 192], [128, 64, 64],
    [64, 192, 128], [64, 64, 0], [128, 64, 128], [128, 128, 192], [0, 0, 192],
    [192, 128, 128], [128, 128, 128], [64, 128, 192], [0, 0, 64], [0, 64, 64],
    [192, 64, 128], [128, 128, 0], [192, 128, 192], [64, 0, 64], [192, 192, 0],
    [0, 0, 0], [64, 192, 0]
]
num_classes = len(COLOR_MAP)
train_labels_one_hot = rgb_to_one_hot(train_labels, num_classes)
val_labels_one_hot = rgb_to_one_hot(val_labels, num_classes)

# Load the trained model
model_path = '/content/data/best_weights.keras'
model = load_model(model_path)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Data generator for training and validation
def data_generator(image_dir, label_dir, batch_size, target_size=(256, 256)):
    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.png')])
    label_files = sorted([f for f in os.listdir(label_dir) if f.endswith('.png')])

    while True:
        for i in range(0, len(image_files), batch_size):
            batch_image_files = image_files[i:i + batch_size]
            batch_label_files = label_files[i:i + batch_size]

            images = []
            labels = []

            for img_file, lbl_file in zip(batch_image_files, batch_label_files):
                img_path = os.path.join(image_dir, img_file)
                lbl_path = os.path.join(label_dir, lbl_file)

                img = Image.open(img_path).convert('RGB')
                img = img.resize(target_size, Image.LANCZOS)
                img_array = np.array(img) / 255.0

                lbl = Image.open(lbl_path).convert('RGB')
                lbl = lbl.resize(target_size, Image.LANCZOS)
                lbl_array = np.array(lbl)
                lbl_one_hot = np.zeros((target_size[0], target_size[1], num_classes))
                for j in range(num_classes):
                    lbl_one_hot[..., j] = np.all(lbl_array == np.array(COLOR_MAP[j]), axis=-1)

                images.append(img_array)
                labels.append(lbl_one_hot)

            yield np.array(images), np.array(labels)

batch_size = 2  # Try reducing the batch size

train_data_gen = data_generator(train_images_dir, train_labels_dir, batch_size)
val_data_gen = data_generator(val_images_dir, val_labels_dir, batch_size)

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)

# Fit the model
history = model.fit(
    train_data_gen,
    steps_per_epoch=len(os.listdir(train_images_dir)) // batch_size,
    validation_data=val_data_gen,
    validation_steps=len(os.listdir(val_images_dir)) // batch_size,
    epochs=50,
    callbacks=[early_stopping, model_checkpoint]
)

# Plot training history
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Over Epochs')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

from google.colab import drive
from tensorflow.keras.models import load_model
import numpy as np
import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt

# Load the model
model_save_path = '/content/data/best_weights.keras'
model = load_model(model_save_path)

# Paths to test images and masks directories
test_images_dir = '/content/data/resized_data/test'
test_masks_dir = '/content/data/resized_data/test_labels'

# Function to load images from a directory
def load_images_from_directory(directory, target_size=(256, 256), color_mode='rgb'):
    images = []
    for filename in sorted(os.listdir(directory)):
        if filename.endswith('.png') or filename.endswith('.jpg'):
            img_path = os.path.join(directory, filename)
            img = load_img(img_path, target_size=target_size, color_mode=color_mode)
            img_array = img_to_array(img)
            images.append(img_array)
    return np.array(images)

# Load test images and masks
test_images = load_images_from_directory(test_images_dir)
test_masks = load_images_from_directory(test_masks_dir, color_mode='rgb')

# Normalize test images if needed (optional, depends on your model's training data preprocessing)
test_images = test_images / 255.0

# Define your class mapping
class_mapping = {
    (64, 128, 64): 0,   # Animal
    (192, 0, 128): 1,   # Archway
    (0, 128, 192): 2,   # Bicyclist
    (0, 128, 64): 3,    # Bridge
    (128, 0, 0): 4,     # Building
    (64, 0, 128): 5,    # Car
    (64, 0, 192): 6,    # CartLuggagePram
    (192, 128, 64): 7,  # Child
    (192, 192, 128): 8, # Column_Pole
    (64, 64, 128): 9,   # Fence
    (128, 0, 192): 10,  # LaneMkgsDriv
    (192, 0, 64): 11,   # LaneMkgsNonDriv
    (128, 128, 64): 12, # Misc_Text
    (192, 0, 192): 13,  # MotorcycleScooter
    (128, 64, 64): 14,  # OtherMoving
    (64, 192, 128): 15, # ParkingBlock
    (64, 64, 0): 16,    # Pedestrian
    (128, 64, 128): 17, # Road
    (128, 128, 192): 18,# RoadShoulder
    (0, 0, 192): 19,   # Sidewalk
    (192, 128, 128): 20,# SignSymbol
    (128, 128, 128): 21,# Sky
    (64, 128, 192): 22,# SUVPickupTruck
    (0, 0, 64): 23,    # TrafficCone
    (0, 64, 64): 24,   # TrafficLight
    (192, 64, 128): 25,# Train
    (128, 128, 0): 26, # Tree
    (192, 128, 192): 27,# Truck_Bus
    (64, 0, 64): 28,   # Tunnel
    (192, 192, 0): 29, # VegetationMisc
    (0, 0, 0): 30,     # Void
    (64, 192, 0): 31   # Wall
}

# Convert RGB masks to categorical format
def rgb_to_categorical(rgb_masks, class_mapping):
    categorical_masks = np.zeros((rgb_masks.shape[0], rgb_masks.shape[1], rgb_masks.shape[2]), dtype=np.uint8)
    for i in range(rgb_masks.shape[0]):
        for color, idx in class_mapping.items():
            mask = np.all(rgb_masks[i] == np.array(color), axis=-1)
            categorical_masks[i][mask] = idx
    return categorical_masks

# Convert test masks to categorical format
test_masks_categorical = rgb_to_categorical(test_masks, class_mapping)

# Convert categorical masks to one-hot encoding format
def to_one_hot(categorical_masks, num_classes):
    one_hot_masks = np.zeros((categorical_masks.shape[0], categorical_masks.shape[1], categorical_masks.shape[2], num_classes), dtype=np.uint8)
    for i in range(num_classes):
        one_hot_masks[..., i] = (categorical_masks == i).astype(np.uint8)
    return one_hot_masks

# Convert test masks to one-hot encoded format
num_classes = len(class_mapping)
test_masks_one_hot = to_one_hot(test_masks_categorical, num_classes)

# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(test_images, test_masks_one_hot, verbose=1)

# Print the results
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

# Predict masks for test images
predicted_masks = model.predict(test_images)

# Convert predicted masks to categorical format
predicted_masks_categorical = np.argmax(predicted_masks, axis=-1)

# Convert predicted masks to RGB format for visualization
def categorical_to_rgb(categorical_masks, color_mapping):
    rgb_masks = np.zeros((categorical_masks.shape[0], categorical_masks.shape[1], categorical_masks.shape[2], 3), dtype=np.uint8)
    for color, idx in color_mapping.items():
        rgb_masks[categorical_masks == idx] = color
    return rgb_masks

# Convert predicted masks to RGB format
predicted_masks_rgb = categorical_to_rgb(predicted_masks_categorical, class_mapping)

# Plot a few test images and their corresponding predicted masks
num_images_to_plot = 5
plt.figure(figsize=(15, 10))
for i in range(num_images_to_plot):
    # Original image
    plt.subplot(3, num_images_to_plot, i + 1)
    plt.imshow(test_images[i].astype('uint8'))
    plt.title("Test Image")
    plt.axis('off')

    # True mask
    plt.subplot(3, num_images_to_plot, i + 1 + num_images_to_plot)
    plt.imshow(categorical_to_rgb(test_masks_categorical[i:i+1], class_mapping).squeeze(), vmin=0, vmax=255)
    plt.title("True Mask")
    plt.axis('off')

    # Predicted mask
    plt.subplot(3, num_images_to_plot, i + 1 + 2 * num_images_to_plot)
    plt.imshow(predicted_masks_rgb[i].astype('uint8'))
    plt.title("Predicted Mask")
    plt.axis('off')

plt.tight_layout()
plt.show()

import numpy as np
import os
from PIL import Image
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Paths to directories
test_images_dir = '/content/data/resized_data/test'
test_labels_dir = '/content/data/resized_data/test_labels'

# Load the testing images and labels from directories
def load_images_from_directory(directory):
    images = []
    for file in sorted(os.listdir(directory)):
        if file.endswith('.png'):
            img_path = os.path.join(directory, file)
            img = Image.open(img_path)
            img = np.array(img)
            images.append(img)
    return np.array(images)

test_images = load_images_from_directory(test_images_dir)
test_labels = load_images_from_directory(test_labels_dir)

# Normalize the images
test_images = test_images.astype('float32') / 255.0

# Convert RGB labels to one-hot encoding
def rgb_to_one_hot(labels, num_classes):
    one_hot_labels = np.zeros((labels.shape[0], labels.shape[1], labels.shape[2], num_classes))
    for i in range(num_classes):
        one_hot_labels[..., i] = np.all(labels == np.array(COLOR_MAP[i]), axis=-1)
    return one_hot_labels

# Define a color map for conversion
COLOR_MAP = [
    [64, 128, 64], [192, 0, 128], [0, 128, 192], [0, 128, 64], [128, 0, 0],
    [64, 0, 128], [64, 0, 192], [192, 128, 64], [192, 192, 128], [64, 64, 128],
    [128, 0, 192], [192, 0, 64], [128, 128, 64], [192, 0, 192], [128, 64, 64],
    [64, 192, 128], [64, 64, 0], [128, 64, 128], [128, 128, 192], [0, 0, 192],
    [192, 128, 128], [128, 128, 128], [64, 128, 192], [0, 0, 64], [0, 64, 64],
    [192, 64, 128], [128, 128, 0], [192, 128, 192], [64, 0, 64], [192, 192, 0],
    [0, 0, 0], [64, 192, 0]
]
num_classes = len(COLOR_MAP)
test_labels_one_hot = rgb_to_one_hot(test_labels, num_classes)

# Load the trained model
model_path = '/content/data/best_weights.keras'
model = load_model(model_path)

# Data augmentation for training (if you have access to training data)
# This is just a placeholder and should be applied during training, not testing
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Evaluate the model on the testing dataset in batches
batch_size = 10
num_batches = len(test_images) // batch_size

test_loss_list = []
test_accuracy_list = []

for i in range(num_batches):
    batch_images = test_images[i*batch_size:(i+1)*batch_size]
    batch_labels = test_labels_one_hot[i*batch_size:(i+1)*batch_size]

    test_loss, test_accuracy = model.evaluate(batch_images, batch_labels, verbose=0)
    test_loss_list.append(test_loss)
    test_accuracy_list.append(test_accuracy)

# Plotting the testing loss and accuracy
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(test_loss_list, label='Test Loss')
plt.xlabel('Batch')
plt.ylabel('Loss')
plt.title('Testing Loss Over Batches')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(test_accuracy_list, label='Test Accuracy')
plt.xlabel('Batch')
plt.ylabel('Accuracy')
plt.title('Testing Accuracy Over Batches')
plt.legend()

plt.tight_layout()
plt.show()

print("Overall Test Loss:", np.mean(test_loss_list))
print("Overall Test Accuracy:", np.mean(test_accuracy_list))

import numpy as np
import os
from PIL import Image
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt

# Paths to directories
test_images_dir = '/content/data/resized_data/test'
test_labels_dir = '/content/data/resized_data/test_labels'

# Define a color map for conversion
COLOR_MAP = [
    [64, 128, 64], [192, 0, 128], [0, 128, 192], [0, 128, 64], [128, 0, 0],
    [64, 0, 128], [64, 0, 192], [192, 128, 64], [192, 192, 128], [64, 64, 128],
    [128, 0, 192], [192, 0, 64], [128, 128, 64], [192, 0, 192], [128, 64, 64],
    [64, 192, 128], [64, 64, 0], [128, 64, 128], [128, 128, 192], [0, 0, 192],
    [192, 128, 128], [128, 128, 128], [64, 128, 192], [0, 0, 64], [0, 64, 64],
    [192, 64, 128], [128, 128, 0], [192, 128, 192], [64, 0, 64], [192, 192, 0],
    [0, 0, 0], [64, 192, 0]
]
num_classes = len(COLOR_MAP)

# Load images and labels from directory
def load_images_from_directory(directory):
    images = []
    for file in sorted(os.listdir(directory)):
        if file.endswith('.png'):
            img_path = os.path.join(directory, file)
            img = Image.open(img_path)
            img = np.array(img)
            images.append(img)
    return np.array(images)

# Load test images and labels
test_images = load_images_from_directory(test_images_dir)
test_labels = load_images_from_directory(test_labels_dir)

# Normalize the images
test_images = test_images.astype('float32') / 255.0

# Convert RGB labels to one-hot encoding
def rgb_to_one_hot(labels, num_classes):
    one_hot_labels = np.zeros((labels.shape[0], labels.shape[1], labels.shape[2], num_classes))
    for i in range(num_classes):
        one_hot_labels[..., i] = np.all(labels == np.array(COLOR_MAP[i]), axis=-1)
    return one_hot_labels

test_labels_one_hot = rgb_to_one_hot(test_labels, num_classes)

# Load the trained model
model_path = '/content/data/best_weights.keras'
model = load_model(model_path)

# Display a sample image and label
def load_and_display_sample(directory, labels_directory, index=0):
    image_files = sorted([f for f in os.listdir(directory) if f.endswith('.png')])
    label_files = sorted([f for f in os.listdir(labels_directory) if f.endswith('.png')])

    img_path = os.path.join(directory, image_files[index])
    label_path = os.path.join(labels_directory, label_files[index])

    img = Image.open(img_path)
    label = Image.open(label_path)

    img = np.array(img)
    label = np.array(label)

    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.title('Image')
    plt.imshow(img)
    plt.subplot(1, 2, 2)
    plt.title('Label')
    plt.imshow(label)
    plt.show()

load_and_display_sample(test_images_dir, test_labels_dir, index=0)

# Check RGB to one-hot conversion
def check_rgb_to_one_hot(labels, num_classes, index=0):
    one_hot_labels = rgb_to_one_hot(labels, num_classes)
    print("One-hot label shape:", one_hot_labels.shape)

    # Print a sample one-hot label
    sample_label = one_hot_labels[index]
    plt.imshow(np.argmax(sample_label, axis=-1))
    plt.title("Sample One-Hot Label")
    plt.show()

check_rgb_to_one_hot(test_labels, num_classes)

# Model predictions on a sample
def model_predictions_on_sample(model, test_images, index=0):
    img = np.expand_dims(test_images[index], axis=0)
    pred = model.predict(img)
    pred = np.squeeze(pred)
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.title('Predicted')
    plt.imshow(np.argmax(pred, axis=-1))
    plt.subplot(1, 2, 2)
    plt.title('True Label')
    plt.imshow(np.argmax(test_labels_one_hot[index], axis=-1))
    plt.show()

model_predictions_on_sample(model, test_images, index=0)

# Evaluate the model on a smaller subset
batch_size = 10
subset_size = 10  # Adjust based on available memory
subset_images = test_images[:subset_size]
subset_labels = test_labels_one_hot[:subset_size]

test_loss, test_accuracy = model.evaluate(subset_images, subset_labels, verbose=1)
print("Subset Test Loss:", test_loss)
print("Subset Test Accuracy:", test_accuracy)

# Initialize lists to collect batch-wise metrics
test_loss_list = []
test_accuracy_list = []

# Evaluate in batches
num_batches = len(test_images) // batch_size

for i in range(num_batches):
    batch_images = test_images[i*batch_size:(i+1)*batch_size]
    batch_labels = test_labels_one_hot[i*batch_size:(i+1)*batch_size]

    test_loss, test_accuracy = model.evaluate(batch_images, batch_labels, verbose=0)
    test_loss_list.append(test_loss)
    test_accuracy_list.append(test_accuracy)

# Plotting the testing loss and accuracy
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(test_loss_list, label='Test Loss')
plt.xlabel('Batch')
plt.ylabel('Loss')
plt.title('Testing Loss Over Batches')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(test_accuracy_list, label='Test Accuracy')
plt.xlabel('Batch')
plt.ylabel('Accuracy')
plt.title('Testing Accuracy Over Batches')
plt.legend()

plt.tight_layout()
plt.show()

print("Overall Test Loss:", np.mean(test_loss_list))
print("Overall Test Accuracy:", np.mean(test_accuracy_list))

import numpy as np
import os
from PIL import Image
from tensorflow.keras.models import load_model
from sklearn.metrics import precision_recall_curve, auc
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize

# Paths to directories
train_images_dir = '/content/data/resized_data/train'
train_labels_dir = '/content/data/resized_data/train_labels'

# Load and resize images from directory
def load_and_resize_images_from_directory(directory, target_size=(256, 256)):
    images = []
    for file in sorted(os.listdir(directory)):
        if file.endswith('.png'):
            img_path = os.path.join(directory, file)
            img = Image.open(img_path).convert('RGB')
            img = img.resize(target_size, Image.LANCZOS)
            images.append(np.array(img))
    return np.array(images)

# Define a color map for conversion
COLOR_MAP = [
    [64, 128, 64], [192, 0, 128], [0, 128, 192], [0, 128, 64], [128, 0, 0],
    [64, 0, 128], [64, 0, 192], [192, 128, 64], [192, 192, 128], [64, 64, 128],
    [128, 0, 192], [192, 0, 64], [128, 128, 64], [192, 0, 192], [128, 64, 64],
    [64, 192, 128], [64, 64, 0], [128, 64, 128], [128, 128, 192], [0, 0, 192],
    [192, 128, 128], [128, 128, 128], [64, 128, 192], [0, 0, 64], [0, 64, 64],
    [192, 64, 128], [128, 128, 0], [192, 128, 192], [64, 0, 64], [192, 192, 0],
    [0, 0, 0], [64, 192, 0]
]
num_classes = len(COLOR_MAP)

# Convert RGB labels to one-hot encoding
def rgb_to_one_hot(labels, num_classes):
    one_hot_labels = np.zeros((labels.shape[0], labels.shape[1], labels.shape[2], num_classes))
    for i in range(num_classes):
        one_hot_labels[..., i] = np.all(labels == np.array(COLOR_MAP[i]), axis=-1)
    return one_hot_labels

# Load the trained model
model_path = '/content/data/best_weights.keras'
model = load_model(model_path)

# Load a subset of training data
num_samples = 50  # Adjust this number based on your dataset size
train_images = load_and_resize_images_from_directory(train_images_dir)[:num_samples]
train_labels = load_and_resize_images_from_directory(train_labels_dir)[:num_samples]
train_labels_one_hot = rgb_to_one_hot(train_labels, num_classes)

# Normalize images
train_images = train_images.astype('float32') / 255.0

# Predict on the subset of training data
train_predictions = model.predict(train_images)

# Define a function to compute and plot Precision-Recall curve
def plot_pr_curve(y_true, y_pred, num_classes):
    # Convert predictions and true masks to binary format
    y_true_bin = np.array([np.argmax(lbl, axis=-1) for lbl in y_true])
    y_pred_bin = np.array([np.argmax(lbl, axis=-1) for lbl in y_pred])

    # Binarize the labels for precision-recall calculation
    y_true_bin = label_binarize(y_true_bin.ravel(), classes=np.arange(num_classes))
    y_pred_bin = label_binarize(y_pred_bin.ravel(), classes=np.arange(num_classes))

    # Compute precision and recall for each class
    precision = dict()
    recall = dict()
    average_precision = dict()
    for i in range(num_classes):
        if np.any(y_true_bin[:, i]):  # Skip classes with no positive samples
            precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_pred_bin[:, i])
            average_precision[i] = auc(recall[i], precision[i])
        else:
            precision[i] = np.array([])
            recall[i] = np.array([])
            average_precision[i] = 0

    # Compute micro-average precision and recall
    precision["micro"], recall["micro"], _ = precision_recall_curve(y_true_bin.ravel(), y_pred_bin.ravel())
    average_precision["micro"] = auc(recall["micro"], precision["micro"])

    # Plot Precision-Recall curve
    plt.figure(figsize=(10, 6))
    plt.plot(recall["micro"], precision["micro"], label='micro-average Precision-Recall curve (AP = {0:0.2f})'.format(average_precision["micro"]))
    for i in range(num_classes):
        if precision[i].size > 0:  # Plot only classes with positive samples
            plt.plot(recall[i], precision[i], label='Class {0} (AP = {1:0.2f})'.format(i, average_precision[i]))

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall curve')
    plt.legend(loc='best')
    plt.show()

# Plot Precision-Recall curve for sampled training data
plot_pr_curve(train_labels_one_hot, train_predictions, num_classes)

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt  # Import matplotlib for plotting

# Define color mappings (RGB triplets to object/class names)
color_mappings = {
    (64, 128, 64): 'Animal',
    (192, 0, 128): 'Archway',
    (0, 128, 192): 'Bicyclist',
    (0, 128, 64): 'Bridge',
    (128, 0, 0): 'Building',
    (64, 0, 128): 'Car',
    (64, 0, 192): 'CartLuggagePram',
    (192, 128, 64): 'Child',
    (192, 192, 128): 'Column_Pole',
    (64, 64, 128): 'Fence',
    (128, 0, 192): 'LaneMkgsDriv',
    (192, 0, 64): 'LaneMkgsNonDriv',
    (128, 128, 64): 'Misc_Text',
    (192, 0, 192): 'MotorcycleScooter',
    (128, 64, 64): 'OtherMoving',
    (64, 192, 128): 'ParkingBlock',
    (64, 64, 0): 'Pedestrian',
    (128, 64, 128): 'Road',
    (128, 128, 192): 'RoadShoulder',
    (0, 0, 192): 'Sidewalk',
    (192, 128, 128): 'SignSymbol',
    (128, 128, 128): 'Sky',
    (64, 128, 192): 'SUVPickupTruck',
    (0, 0, 64): 'TrafficCone',
    (0, 64, 64): 'TrafficLight',
    (192, 64, 128): 'Train',
    (128, 128, 0): 'Tree',
    (192, 128, 192): 'Truck_Bus',
    (64, 0, 64): 'Tunnel',
    (192, 192, 0): 'VegetationMisc',
    (0, 0, 0): 'Void',
    (64, 192, 0): 'Wall'
}

# Directories containing annotations/masks
train_dir = '/content/data/resized_data/train_labels'
val_dir = '/content/data/resized_data/val_labels'
test_dir = '/content/data/resized_data/test_labels'

# Function to count occurrences of each object/class in annotations
def count_object_occurrences(annotations_dir, color_mappings):
    object_counts = {obj: 0 for obj in color_mappings.values()}

    # List all annotation files
    annotation_files = sorted(os.listdir(annotations_dir))

    for filename in annotation_files:
        # Load annotation mask
        mask = np.array(Image.open(os.path.join(annotations_dir, filename)))

        # Count occurrences of each object/class
        unique_colors = np.unique(mask.reshape(-1, mask.shape[2]), axis=0)
        for color in unique_colors:
            color_tuple = tuple(color)
            if color_tuple in color_mappings:
                object_name = color_mappings[color_tuple]
                object_counts[object_name] += np.sum(np.all(mask == color, axis=-1))

    return object_counts

# Count occurrences for each dataset
train_occurrences = count_object_occurrences(train_dir, color_mappings)
val_occurrences = count_object_occurrences(val_dir, color_mappings)
test_occurrences = count_object_occurrences(test_dir, color_mappings)

# Print results
print("Train Set:")
for obj, count in train_occurrences.items():
    print(f"{obj}: {count}")

print("\nValidation Set:")
for obj, count in val_occurrences.items():
    print(f"{obj}: {count}")

print("\nTest Set:")
for obj, count in test_occurrences.items():
    print(f"{obj}: {count}")

# Plotting histograms
def plot_histogram(data, title):
    objects = list(data.keys())
    counts = list(data.values())

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.bar(objects, counts, color='skyblue')
    ax.set_xlabel('Object/Class')
    ax.set_ylabel('Count')
    ax.set_title(title)
    plt.xticks(rotation=90)
    plt.tight_layout()
    plt.show()

plot_histogram(train_occurrences, 'Train Set Object Occurrences')
plot_histogram(val_occurrences, 'Validation Set Object Occurrences')
plot_histogram(test_occurrences, 'Test Set Object Occurrences')

# Counts of pixels for each class in each dataset split
train_counts = {
    'Animal': 1024,
    'Archway': 10294,
    'Bicyclist': 107609,
    'Bridge': 10003,
    'Building': 5420099,
    'Car': 735036,
    'CartLuggagePram': 5376,
    'Child': 6478,
    'Column_Pole': 183203,
    'Fence': 390010,
    'LaneMkgsDriv': 358720,
    'LaneMkgsNonDriv': 1987,
    'Misc_Text': 148195,
    'MotorcycleScooter': 1226,
    'OtherMoving': 104336,
    'ParkingBlock': 80991,
    'Pedestrian': 132342,
    'Road': 6772458,
    'RoadShoulder': 55837,
    'Sidewalk': 1605098,
    'SignSymbol': 28210,
    'Sky': 3515234,
    'SUVPickupTruck': 124469,
    'TrafficCone': 804,
    'TrafficLight': 80566,
    'Train': 1,
    'Tree': 2354496,
    'Truck_Bus': 43406,
    'Tunnel': 0,
    'VegetationMisc': 189040,
    'Void': 531599,
    'Wall': 283002
}

val_counts = {
    'Animal': 186,
    'Archway': 14070,
    'Bicyclist': 29960,
    'Bridge': 1652,
    'Building': 1443092,
    'Car': 231363,
    'CartLuggagePram': 2189,
    'Child': 1120,
    'Column_Pole': 47894,
    'Fence': 79614,
    'LaneMkgsDriv': 86881,
    'LaneMkgsNonDriv': 2574,
    'Misc_Text': 36348,
    'MotorcycleScooter': 371,
    'OtherMoving': 21686,
    'ParkingBlock': 14785,
    'Pedestrian': 35152,
    'Road': 1850279,
    'RoadShoulder': 25134,
    'Sidewalk': 380177,
    'SignSymbol': 6445,
    'Sky': 990616,
    'SUVPickupTruck': 47432,
    'TrafficCone': 319,
    'TrafficLight': 25421,
    'Train': 0,
    'Tree': 644174,
    'Truck_Bus': 27213,
    'Tunnel': 0,
    'VegetationMisc': 59264,
    'Void': 129057,
    'Wall': 74423
}

test_counts = {
    'Animal': 768,
    'Archway': 3008,
    'Bicyclist': 89587,
    'Bridge': 8371,
    'Building': 3412886,
    'Car': 559967,
    'CartLuggagePram': 4253,
    'Child': 3396,
    'Column_Pole': 97922,
    'Fence': 162465,
    'LaneMkgsDriv': 167978,
    'LaneMkgsNonDriv': 285,
    'Misc_Text': 65185,
    'MotorcycleScooter': 2751,
    'OtherMoving': 41850,
    'ParkingBlock': 49433,
    'Pedestrian': 91978,
    'Road': 3671888,
    'RoadShoulder': 30818,
    'Sidewalk': 846607,
    'SignSymbol': 14455,
    'Sky': 2518082,
    'SUVPickupTruck': 141352,
    'TrafficCone': 129,
    'TrafficLight': 50748,
    'Train': 0,
    'Tree': 1619122,
    'Truck_Bus': 171156,
    'Tunnel': 0,
    'VegetationMisc': 86165,
    'Void': 522257,
    'Wall': 233664
}

# Function to calculate class-wise accuracies
def calculate_class_accuracies(counts):
    accuracies = {}
    for obj, total_pixels in counts.items():
        accuracies[obj] = total_pixels / sum(counts.values()) * 100
    return accuracies

# Calculate class-wise accuracies for each dataset split
train_accuracies = calculate_class_accuracies(train_counts)
val_accuracies = calculate_class_accuracies(val_counts)
test_accuracies = calculate_class_accuracies(test_counts)


print("Accuracies:")
for obj, acc in test_accuracies.items():
    print(f"{obj}: {acc:.2f}%")

import matplotlib.pyplot as plt

# Function to calculate class-wise accuracies
def calculate_class_accuracies(counts):
    accuracies = {}
    for obj, total_pixels in counts.items():
        accuracies[obj] = total_pixels / sum(counts.values()) * 100
    return accuracies

# Calculate class-wise accuracies for each dataset split
train_accuracies = calculate_class_accuracies(train_counts)
val_accuracies = calculate_class_accuracies(val_counts)
test_accuracies = calculate_class_accuracies(test_counts)

# Function to plot histogram for accuracies
def plot_accuracies(accuracies, title):
    objects = list(accuracies.keys())
    values = list(accuracies.values())

    plt.figure(figsize=(12, 8))
    plt.barh(objects, values, color='skyblue')
    plt.xlabel('Accuracy (%)')
    plt.title(title)
    plt.grid(axis='x')
    plt.tight_layout()
    plt.show()

# Plot histograms for each dataset split
plot_accuracies(train_accuracies, 'Train Set Class-Wise Accuracies')
plot_accuracies(val_accuracies, 'Validation Set Class-Wise Accuracies')
plot_accuracies(test_accuracies, 'Test Set Class-Wise Accuracies')